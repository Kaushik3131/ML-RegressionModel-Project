{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89cf7200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.4\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "260096cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\ML-projects\\Regression_ML_EndtoEnd\\.venv\\Scripts\\python.exe\n",
      "3.0.4\n",
      "e:\\ML-projects\\Regression_ML_EndtoEnd\\.venv\\Lib\\site-packages\\xgboost\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys, xgboost as xgb\n",
    "print(sys.executable)        # should point to .../.venv/bin/python\n",
    "print(xgb.__version__)       # should print 3.0.4\n",
    "print(xgb.__file__)          # should live under .../.venv/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478bf394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ML-projects\\Regression_ML_EndtoEnd\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 1. Imports\n",
    "# ==============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0bc804c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (585199, 41)\n",
      "Eval shape: (149423, 41)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 2. Load processed datasets\n",
    "# ==============================================\n",
    "train_df = pd.read_csv(\"E:/ML-projects/Regression_ML_EndtoEnd/data/processed/feature_engineered_train.csv\")\n",
    "eval_df  = pd.read_csv(\"E:/ML-projects/Regression_ML_EndtoEnd/data/processed/feature_engineered_eval.csv\")\n",
    "\n",
    "\n",
    "# Define target + features\n",
    "target = \"price\"\n",
    "X_train, y_train = train_df.drop(columns=[target]), train_df[target]\n",
    "X_eval, y_eval   = eval_df.drop(columns=[target]), eval_df[target]\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Eval shape:\", X_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fadb78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clean data for XGBoost inside Optuna\n",
    "X_train_clean = X_train.select_dtypes(include=['int', 'float', 'bool']).copy().fillna(0)\n",
    "X_eval_clean  = X_eval.select_dtypes(include=['int', 'float', 'bool']).copy().fillna(0)\n",
    "\n",
    "# ensure alignment (if eval lacks some one-hot cols)\n",
    "X_eval_clean = X_eval_clean.reindex(columns=X_train_clean.columns, fill_value=0)\n",
    "\n",
    "# convert targets to numeric arrays\n",
    "y_train_arr = pd.to_numeric(y_train, errors='coerce').fillna(0).values\n",
    "y_eval_arr  = pd.to_numeric(y_eval,  errors='coerce').fillna(0).values\n",
    "\n",
    "# convert features to numpy arrays (safe for XGBoost)\n",
    "X_train_arr = X_train_clean.values.astype(float)\n",
    "X_eval_arr  = X_eval_clean.values.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "992ebfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"tree_method\": \"hist\",\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(X_train_arr, y_train_arr)\n",
    "\n",
    "        y_pred = model.predict(X_eval_arr)\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_eval_arr, y_pred)))\n",
    "        mae = float(mean_absolute_error(y_eval_arr, y_pred))\n",
    "        r2 = float(r2_score(y_eval_arr, y_pred))\n",
    "\n",
    "        # Log hyperparameters + metrics\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\"rmse\": rmse, \"mae\": mae, \"r2\": r2})\n",
    "\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ed4b5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-04 18:55:05,360] A new study created in memory with name: no-name-ce8f4219-2c9b-4996-8148-7f41035779d1\n",
      "[I 2025-12-04 18:55:59,777] Trial 0 finished with value: 71841.890161622 and parameters: {'n_estimators': 883, 'max_depth': 8, 'learning_rate': 0.17291816398468443, 'subsample': 0.8250132462170008, 'colsample_bytree': 0.7544216655956326, 'min_child_weight': 10, 'gamma': 0.5485407744160431, 'reg_alpha': 0.0010002124038078224, 'reg_lambda': 2.183273615473709e-08}. Best is trial 0 with value: 71841.890161622.\n",
      "[I 2025-12-04 18:56:19,177] Trial 1 finished with value: 74230.75463324043 and parameters: {'n_estimators': 373, 'max_depth': 6, 'learning_rate': 0.06220731239227764, 'subsample': 0.9912734435193371, 'colsample_bytree': 0.8463635211126092, 'min_child_weight': 6, 'gamma': 2.4520268007858324, 'reg_alpha': 8.135632749590608e-07, 'reg_lambda': 5.048783650311177e-08}. Best is trial 0 with value: 71841.890161622.\n",
      "[I 2025-12-04 18:57:33,647] Trial 2 finished with value: 80178.97588390192 and parameters: {'n_estimators': 693, 'max_depth': 10, 'learning_rate': 0.08307141015429999, 'subsample': 0.9537411456071923, 'colsample_bytree': 0.9914651429309431, 'min_child_weight': 4, 'gamma': 0.3780629235485683, 'reg_alpha': 0.0006642881200683939, 'reg_lambda': 1.1052655405736545e-08}. Best is trial 0 with value: 71841.890161622.\n",
      "[I 2025-12-04 18:58:45,156] Trial 3 finished with value: 81276.51134125759 and parameters: {'n_estimators': 922, 'max_depth': 9, 'learning_rate': 0.18374595000977334, 'subsample': 0.7405716645590799, 'colsample_bytree': 0.9772052055962502, 'min_child_weight': 5, 'gamma': 4.849321595634301, 'reg_alpha': 7.610845713820702, 'reg_lambda': 4.193800416813556e-05}. Best is trial 0 with value: 71841.890161622.\n",
      "[I 2025-12-04 18:58:55,332] Trial 4 finished with value: 75219.6949904029 and parameters: {'n_estimators': 236, 'max_depth': 4, 'learning_rate': 0.16449295808166256, 'subsample': 0.9208374224433475, 'colsample_bytree': 0.9280088677295999, 'min_child_weight': 8, 'gamma': 2.4398968066029965, 'reg_alpha': 1.3020413455151614, 'reg_lambda': 0.003945837974693808}. Best is trial 0 with value: 71841.890161622.\n",
      "[I 2025-12-04 18:59:24,411] Trial 5 finished with value: 73954.29094795871 and parameters: {'n_estimators': 882, 'max_depth': 3, 'learning_rate': 0.08154137643394932, 'subsample': 0.7445928598897318, 'colsample_bytree': 0.5119136973178616, 'min_child_weight': 7, 'gamma': 2.334284334542506, 'reg_alpha': 0.3382693953194046, 'reg_lambda': 0.00884194509915956}. Best is trial 0 with value: 71841.890161622.\n",
      "[I 2025-12-04 19:00:17,832] Trial 6 finished with value: 66655.10270094978 and parameters: {'n_estimators': 972, 'max_depth': 7, 'learning_rate': 0.01665047753301653, 'subsample': 0.6473727417618036, 'colsample_bytree': 0.5872451008176716, 'min_child_weight': 9, 'gamma': 4.580734813590646, 'reg_alpha': 0.41930002204526357, 'reg_lambda': 0.00898058457669847}. Best is trial 6 with value: 66655.10270094978.\n",
      "[I 2025-12-04 19:00:47,196] Trial 7 finished with value: 73496.86685131784 and parameters: {'n_estimators': 541, 'max_depth': 6, 'learning_rate': 0.0130806762365, 'subsample': 0.7462555645731097, 'colsample_bytree': 0.5443268279486304, 'min_child_weight': 8, 'gamma': 4.296584104243259, 'reg_alpha': 0.009885524555343599, 'reg_lambda': 2.274814264304361e-06}. Best is trial 6 with value: 66655.10270094978.\n",
      "[I 2025-12-04 19:01:05,556] Trial 8 finished with value: 73956.76136866432 and parameters: {'n_estimators': 313, 'max_depth': 7, 'learning_rate': 0.05276519381838497, 'subsample': 0.8813501718797135, 'colsample_bytree': 0.9465738841624797, 'min_child_weight': 4, 'gamma': 2.097421642574619, 'reg_alpha': 2.9341323876361224e-06, 'reg_lambda': 4.919039661392338}. Best is trial 6 with value: 66655.10270094978.\n",
      "[I 2025-12-04 19:01:29,740] Trial 9 finished with value: 76988.7172939269 and parameters: {'n_estimators': 301, 'max_depth': 9, 'learning_rate': 0.20024628786232304, 'subsample': 0.5463121915315987, 'colsample_bytree': 0.9520277465651041, 'min_child_weight': 5, 'gamma': 2.5181911462159157, 'reg_alpha': 0.16616962391695442, 'reg_lambda': 2.622372149897284e-07}. Best is trial 6 with value: 66655.10270094978.\n",
      "[I 2025-12-04 19:02:03,375] Trial 10 finished with value: 78548.9272693886 and parameters: {'n_estimators': 703, 'max_depth': 5, 'learning_rate': 0.010960689622512473, 'subsample': 0.5924513824113823, 'colsample_bytree': 0.6266379440587767, 'min_child_weight': 1, 'gamma': 3.7045143905166036, 'reg_alpha': 2.848959489718718e-08, 'reg_lambda': 1.400854813626015}. Best is trial 6 with value: 66655.10270094978.\n",
      "[I 2025-12-04 19:03:05,300] Trial 11 finished with value: 66460.84380688368 and parameters: {'n_estimators': 972, 'max_depth': 8, 'learning_rate': 0.02493391530771888, 'subsample': 0.652047482111805, 'colsample_bytree': 0.7182346732160855, 'min_child_weight': 10, 'gamma': 0.6021729493091406, 'reg_alpha': 0.00036396077285295815, 'reg_lambda': 0.025420258726613153}. Best is trial 11 with value: 66460.84380688368.\n",
      "[I 2025-12-04 19:03:58,737] Trial 12 finished with value: 67646.00050423353 and parameters: {'n_estimators': 980, 'max_depth': 7, 'learning_rate': 0.021241211622048676, 'subsample': 0.62360278350306, 'colsample_bytree': 0.6641293216297347, 'min_child_weight': 10, 'gamma': 1.0667335109624296, 'reg_alpha': 1.8022161851398164e-05, 'reg_lambda': 0.03350606391435141}. Best is trial 11 with value: 66460.84380688368.\n",
      "[I 2025-12-04 19:04:49,107] Trial 13 finished with value: 68176.87036676223 and parameters: {'n_estimators': 776, 'max_depth': 8, 'learning_rate': 0.027142529018195277, 'subsample': 0.6380576144866366, 'colsample_bytree': 0.728969139246919, 'min_child_weight': 9, 'gamma': 3.5200667939931147, 'reg_alpha': 0.029976846151788493, 'reg_lambda': 0.16514897563327147}. Best is trial 11 with value: 66460.84380688368.\n",
      "[I 2025-12-04 19:05:25,255] Trial 14 finished with value: 66867.6764776906 and parameters: {'n_estimators': 534, 'max_depth': 8, 'learning_rate': 0.02766769105015855, 'subsample': 0.6732320576094144, 'colsample_bytree': 0.6027657226861709, 'min_child_weight': 10, 'gamma': 1.5071033095070776, 'reg_alpha': 5.9404607598315725e-05, 'reg_lambda': 0.0003880274061301745}. Best is trial 11 with value: 66460.84380688368.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 972, 'max_depth': 8, 'learning_rate': 0.02493391530771888, 'subsample': 0.652047482111805, 'colsample_bytree': 0.7182346732160855, 'min_child_weight': 10, 'gamma': 0.6021729493091406, 'reg_alpha': 0.00036396077285295815, 'reg_lambda': 0.025420258726613153}\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 4. Run Optuna study with MLflow\n",
    "# ==============================================\n",
    "# Force MLflow to always use the root project mlruns folder\n",
    "mlflow.set_tracking_uri(\"file:///E:/ML-projects/Regression_ML_EndtoEnd/mlruns\")\n",
    "mlflow.set_experiment(\"xgboost_optuna_housing\")\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "print(\"Best params:\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21b8c223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final tuned model performance:\n",
      "MAE: 30997.338523443355\n",
      "RMSE: 69906.80442135924\n",
      "R²: 0.9621859198715181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ML-projects\\Regression_ML_EndtoEnd\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1028: UserWarning: [23:35:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\c_api\\c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "2025/12/04 23:36:02 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/12/04 23:36:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 5. Train final model with best params and log to MLflow\n",
    "# ==============================================\n",
    "best_params = study.best_trial.params\n",
    "best_model = XGBRegressor(**best_params)\n",
    "best_model.fit(X_train_arr, y_train_arr)\n",
    "\n",
    "y_pred = best_model.predict(X_eval_arr)\n",
    "\n",
    "mae = mean_absolute_error(y_eval_arr, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_eval_arr, y_pred))\n",
    "r2 = r2_score(y_eval_arr, y_pred)\n",
    "\n",
    "print(\"Final tuned model performance:\")\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R²:\", r2)\n",
    "\n",
    "# Log final model\n",
    "with mlflow.start_run(run_name=\"best_xgboost_model\"):\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metrics({\"rmse\": rmse, \"mae\": mae, \"r2\": r2})\n",
    "    mlflow.xgboost.log_model(best_model, name=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c1be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "housing-regression-mle (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
